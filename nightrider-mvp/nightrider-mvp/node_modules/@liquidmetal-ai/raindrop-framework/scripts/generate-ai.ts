#!/usr/bin/env node
/* eslint-disable */

import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';
import { compile } from 'json-schema-to-typescript';

// Get __dirname equivalent for ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration
const CLOUDFLARE_ACCOUNT_ID = process.env.CLOUDFLARE_ACCOUNT_ID;
const CLOUDFLARE_API_TOKEN = process.env.CLOUDFLARE_API_TOKEN;
const OUTPUT_FILE = process.env.OUTPUT_FILE || 'src/ai.ts';
const CUSTOM_MODELS_FILE = process.env.CUSTOM_MODELS_FILE || path.join(__dirname, 'custom-models.json');
const MODEL_ROUTER_CONFIG = process.env.MODEL_ROUTER_CONFIG || path.join(__dirname, '../../../gcp/lm-model-router/config.json');

if (!CLOUDFLARE_ACCOUNT_ID || !CLOUDFLARE_API_TOKEN) {
  console.error('Please set CLOUDFLARE_ACCOUNT_ID and CLOUDFLARE_API_TOKEN environment variables');
  process.exit(1);
}

interface ApiModel {
  id: string;
  name: string;
  description: string;
  task: {
    id: string;
    name: string;
    description: string;
  };
  created_at: string;
  tags: string[];
  properties: Array<{
    property_id: string;
    value: string | Array<{ unit: string; price: number; currency: string }>;
  }>;
}

interface JsonSchema {
  type?: string;
  properties?: Record<string, JsonSchema>;
  items?: JsonSchema;
  oneOf?: JsonSchema[];
  anyOf?: JsonSchema[];
  allOf?: JsonSchema[];
  required?: string[];
  enum?: string[];
  description?: string;
  minLength?: number;
  maxItems?: number;
  default?: any;
  contentType?: string;
  title?: string;
  format?: string;
  minimum?: number;
  maximum?: number;
}

interface ModelSchema {
  success: boolean;
  result?: {
    input?: JsonSchema;
    output?: JsonSchema;
  };
}

interface ApiResponse {
  success: boolean;
  result?: ApiModel[];
}

interface CustomModel {
  name: string;
  description: string;
  task: {
    id: string;
    name: string;
    description: string;
  };
  schema: {
    input?: JsonSchema;
    output?: JsonSchema;
  };
}

interface CustomModelsConfig {
  models: CustomModel[];
}

interface ModelRouterProvider {
  name: string;
  type: string;
  models: string[];
  modelMapping?: Record<string, string>;
}

interface ModelRouterConfig {
  providers: ModelRouterProvider[];
  routing: Record<string, string[]>;
}

// Model name mapping from technical names to user-friendly names
const MODEL_NAME_MAPPING: Record<string, string> = {
  // Mistral models - prefer the base version
  'mistral-7b-instruct-v0.1': 'mistral-7b-instruct',
  'mistral-7b-instruct-v0.2': 'mistral-7b-instruct-v0.2',
  'mistral-7b-instruct-v0.2-lora': 'mistral-7b-instruct-v0.2-lora',
  'mistral-7b-instruct-v0.1-awq': 'mistral-7b-instruct-awq',
  
  // Gemma models - prefer simple name
  'gemma-2b-it-lora': 'gemma-2b',
  'gemma-7b-it-lora': 'gemma-7b',
  'gemma-3-12b-it': 'gemma-3-12b',
  
  // BGE models - remove version suffixes
  'bge-large-en-v1.5': 'bge-large-en',
  'bge-base-en-v1.5': 'bge-base-en', 
  'bge-small-en-v1.5': 'bge-small-en',
  
  // Llama models - clean up versions
  'llama-3.3-70b-instruct-fp8-fast': 'llama-3.3-70b-instruct-fp8',
  'llama-3.2-11b-vision-instruct': 'llama-3.2-11b-vision',
  'llama-4-scout-17b-16e-instruct': 'llama-4-scout-17b',
  
  // Whisper models
  'whisper-large-v3-turbo': 'whisper-large-v3-turbo',
  'whisper-tiny-en': 'whisper-tiny',
  
  // GPT models
  'gpt-oss-120b': 'gpt-oss-120b',
  'gpt-oss-20b': 'gpt-oss-20b',
  
  // Qwen models - simplify
  'qwen1.5-0.5b-chat': 'qwen-1.5-0.5b',
  'qwen1.5-1.8b-chat': 'qwen-1.5-1.8b', 
  'qwen1.5-7b-chat-awq': 'qwen-1.5-7b',
  'qwen1.5-14b-chat-awq': 'qwen-1.5-14b',
  'qwen2.5-coder-32b-instruct': 'qwen-coder-32b',
  'qwq-32b': 'qwen-qwq-32b',
  
  // DeepSeek models
  'deepseek-r1-distill-qwen-32b': 'deepseek-r1-distill-qwen-32b',
  'deepseek-math-7b-instruct': 'deepseek-math-7b',
  'deepseek-coder-6.7b-base-awq': 'deepseek-coder-6.7b-base',
  'deepseek-coder-6.7b-instruct-awq': 'deepseek-coder-6.7b',
  
  // Vision models
  'llava-1.5-7b-hf': 'llava-1.5-7b',
  
  // Other models - clean up
  'mistral-small-3.1-24b-instruct': 'mistral-small-3.1',
  'openchat-3.5-0106': 'openchat-3.5',
  'sqlcoder-7b-2': 'sqlcoder-7b',
  'phi-2': 'phi-2',
};

async function fetchModels(): Promise<ApiModel[]> {
  const allModels: ApiModel[] = [];
  let page = 1;
  let hasMore = true;

  while (hasMore) {
    console.log(`Fetching page ${page}...`);

    const response = await fetch(
      `https://api.cloudflare.com/client/v4/accounts/${CLOUDFLARE_ACCOUNT_ID}/ai/models/search?page=${page}&per_page=100`,
      {
        headers: {
          'Authorization': `Bearer ${CLOUDFLARE_API_TOKEN}`,
          'Content-Type': 'application/json'
        }
      }
    );

    if (!response.ok) {
      throw new Error(`Failed to fetch models: ${response.statusText}`);
    }

    const data = await response.json() as ApiResponse & {
      result_info?: {
        count: number;
        page: number;
        per_page: number;
        total_count: number;
      };
    };

    console.log(`Page ${page} response:`, {
      resultCount: data.result?.length || 0,
      resultInfo: data.result_info
    });

    if (data.result) {
      allModels.push(...data.result);
    }

    // Check if we need to fetch more pages
    if (data.result_info) {
      const { page: currentPage, per_page, total_count } = data.result_info;
      hasMore = currentPage * per_page < total_count;
      console.log(`Pagination: page=${currentPage}, per_page=${per_page}, total_count=${total_count}, hasMore=${hasMore}`);
      page++;
    } else {
      // Fallback: if no result_info, check if we got fewer results than requested
      const receivedCount = data.result?.length || 0;
      hasMore = receivedCount >= 100; // Continue if we got a full page
      console.log(`No result_info, received ${receivedCount} results, hasMore=${hasMore}`);
      page++;
    }

    // Safety check to prevent infinite loops
    if (page > 50) {
      console.warn('Stopping pagination after 50 pages to prevent infinite loop');
      break;
    }
  }

  console.log(`Total models fetched: ${allModels.length}`);
  return allModels;
}

async function fetchSchema(modelName: string, retries: number = 3): Promise<ModelSchema | null> {
  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      const response = await fetch(
        `https://api.cloudflare.com/client/v4/accounts/${CLOUDFLARE_ACCOUNT_ID}/ai/models/schema?model=${encodeURIComponent(modelName)}`,
        {
          headers: {
            'Authorization': `Bearer ${CLOUDFLARE_API_TOKEN}`,
            'Content-Type': 'application/json'
          }
        }
      );

      if (!response.ok) {
        if (response.status === 429) {
          // Rate limited, wait and retry
          const waitTime = Math.min(1000 * Math.pow(2, attempt - 1), 10000);
          console.log(`Rate limited for ${modelName}, waiting ${waitTime}ms before retry ${attempt}/${retries}`);
          await new Promise(resolve => setTimeout(resolve, waitTime));
          continue;
        }
        console.warn(`Failed to fetch schema for ${modelName}: ${response.statusText} (attempt ${attempt}/${retries})`);
        if (attempt === retries) return null;
        continue;
      }

      const data = await response.json() as ModelSchema;
      return data;
    } catch (error) {
      console.warn(`Error fetching schema for ${modelName}: ${error} (attempt ${attempt}/${retries})`);
      if (attempt === retries) return null;

      // Wait before retry
      const waitTime = Math.min(1000 * Math.pow(2, attempt - 1), 5000);
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
  }

  return null;
}

// Helper function to batch promises with concurrency limit
async function batchPromises<T>(
  items: T[],
  processor: (item: T) => Promise<any>,
  concurrency: number = 10
): Promise<void> {
  const results: Promise<any>[] = [];
  let index = 0;

  while (index < items.length) {
    const batch = items.slice(index, index + concurrency);
    const batchPromises = batch.map(processor);
    results.push(...batchPromises);

    // Wait for this batch to complete before starting the next
    await Promise.all(batchPromises);
    index += concurrency;

    // Small delay between batches to avoid overwhelming the API
    if (index < items.length) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }
  }
}

function groupModelsByTask(models: ApiModel[]): Record<string, ApiModel[]> {
  const groups: Record<string, ApiModel[]> = {};

  models.forEach(model => {
    const taskName = model.task?.name;
    if (!taskName) return;

    if (!groups[taskName]) {
      groups[taskName] = [];
    }

    groups[taskName].push(model);
  });

  return groups;
}

function hasAsyncResponseInSchema(schema: JsonSchema): boolean {
  // Check if this schema contains an AsyncResponse-like structure
  if (schema.type === 'object' && schema.properties) {
    // Check for request_id property which indicates an async response
    if (schema.properties.request_id) {
      return true;
    }
  }

  // Check oneOf/anyOf arrays
  if (schema.oneOf) {
    return schema.oneOf.some(s => hasAsyncResponseInSchema(s));
  }
  if (schema.anyOf) {
    return schema.anyOf.some(s => hasAsyncResponseInSchema(s));
  }

  // Check nested properties
  if (schema.properties) {
    return Object.values(schema.properties).some(s => hasAsyncResponseInSchema(s));
  }

  // Check array items
  if (schema.items) {
    return hasAsyncResponseInSchema(schema.items);
  }

  return false;
}

async function generateTypeFromSchema(schema: JsonSchema, typeName: string, modelName: string, usedTypeNames: Set<string>, isOutput: boolean = false): Promise<string> {
  try {
    let modifiedSchema = schema;
    let notes: string[] = [];

    // If this is an output schema, handle special cases
    if (isOutput) {
      // Handle async response
      if (hasAsyncResponseInSchema(schema)) {
        // Check if it's a oneOf with async response
        if (schema.oneOf && schema.oneOf.some(s => s.type === 'object' && s.properties?.request_id)) {
          // Find the non-async response schemas
          const nonAsyncSchemas = schema.oneOf.filter(s => !(s.type === 'object' && s.properties?.request_id));

          if (nonAsyncSchemas.length > 0) {
            // Generate type for non-async responses only
            modifiedSchema = nonAsyncSchemas.length === 1
              ? nonAsyncSchemas[0]
              : { oneOf: nonAsyncSchemas };

            notes.push('This type excludes AsyncResponse variants which are handled by the queueRequest option');
          }
        }
      }

      // Remove string from oneOf/anyOf if there are object types present
      if (modifiedSchema.oneOf) {
        const hasObjectType = modifiedSchema.oneOf.some(s => s.type === 'object');
        const hasStringType = modifiedSchema.oneOf.some(s => s.type === 'string');

        if (hasObjectType && hasStringType) {
          // Filter out string types when object types are present
          modifiedSchema = {
            ...modifiedSchema,
            oneOf: modifiedSchema.oneOf.filter(s => s.type !== 'string')
          };

          // If only one schema remains, unwrap it
          if (modifiedSchema.oneOf.length === 1) {
            modifiedSchema = modifiedSchema.oneOf[0];
          }
        }
      }

      if (modifiedSchema.anyOf) {
        const hasObjectType = modifiedSchema.anyOf.some(s => s.type === 'object');
        const hasStringType = modifiedSchema.anyOf.some(s => s.type === 'string');

        if (hasObjectType && hasStringType) {
          // Filter out string types when object types are present
          modifiedSchema = {
            ...modifiedSchema,
            anyOf: modifiedSchema.anyOf.filter(s => s.type !== 'string')
          };

          // If only one schema remains, unwrap it
          if (modifiedSchema.anyOf.length === 1) {
            modifiedSchema = modifiedSchema.anyOf[0];
          }
        }
      }
    }

    const generatedType = await generateTypeFromSchemaInternal(modifiedSchema, typeName, modelName, usedTypeNames);

    // Add notes if any
    if (notes.length > 0) {
      return `// Note: ${notes.join('; ')}
${generatedType}`;
    }

    return generatedType;
  } catch (error) {
    console.error(`Failed to generate TypeScript for ${typeName}:`, error);
    console.error('Schema:', JSON.stringify(schema, null, 2));
    // Return a more detailed fallback type
    return `export type ${typeName} = {
  // Failed to generate from schema: ${error instanceof Error ? error.message : 'Unknown error'}
  [key: string]: unknown;
};`;
  }
}

async function generateTypeFromSchemaInternal(schema: JsonSchema, typeName: string, modelName: string, usedTypeNames: Set<string>): Promise<string> {
  const tsType = await compile(schema as any, typeName, {
    bannerComment: '',
    style: {
      semi: true,
      singleQuote: true,
      tabWidth: 2,
      useTabs: false,
    },
    unreachableDefinitions: true,
    unknownAny: false,
    declareExternallyReferenced: true,
    additionalProperties: false,
    enableConstEnums: true,
    strictIndexSignatures: false,
    ignoreMinAndMaxItems: true, // Ignore min/max items that might affect naming
    format: false, // Disable format validation that might interfere
  });

  // Post-process the generated TypeScript to ensure ALL type names are unique
  // This handles cases where json-schema-to-typescript generates its own interface names
  const processedType = postProcessGeneratedTypes(tsType, typeName, modelName, usedTypeNames);

  return processedType.trim();
}

function postProcessGeneratedTypes(tsCode: string, rootTypeName: string, modelName: string, usedTypeNames: Set<string>): string {
  // Replace special characters in model name to make it a valid identifier
  const safeModelName = modelName.replace(/[^a-zA-Z0-9]/g, '_');

  // First, ensure the main interface/type uses the correct name
  // Replace common patterns that json-schema-to-typescript might generate
  let processedCode = tsCode;
  
  // Replace GPT_OSS_Responses or similar generated names with our desired name
  const commonPatterns = [
    /export interface GPT_OSS_Responses/g,
    /export type GPT_OSS_Responses/g,
    /interface GPT_OSS_Responses/g,
    /type GPT_OSS_Responses/g
  ];
  
  for (const pattern of commonPatterns) {
    const replacement = `export interface ${rootTypeName}`;
    processedCode = processedCode.replace(pattern, replacement);
  }

  // Find all interface and type declarations
  const typePattern = /^(export\s+)?(interface|type)\s+(\w+)/gm;
  const replacements: Array<[string, string]> = [];

  let match;
  while ((match = typePattern.exec(processedCode)) !== null) {
    const originalName = match[3];
    
    // Skip if match didn't capture the type name
    if (!originalName) {
      continue;
    }

    // Skip if it's the root type name
    if (originalName === rootTypeName) {
      continue;
    }

    // Check if this type name was already used
    if (usedTypeNames.has(originalName)) {
      // Generate a unique name
      let newName = `${safeModelName}_${rootTypeName}_${originalName}`;
      let counter = 1;

      while (usedTypeNames.has(newName)) {
        newName = `${safeModelName}_${rootTypeName}_${originalName}_${counter}`;
        counter++;
      }

      usedTypeNames.add(newName);
      replacements.push([originalName, newName]);
    } else {
      // Mark this name as used
      usedTypeNames.add(originalName);
    }
  }

  // Apply replacements
  let finalCode = processedCode;
  for (const [oldName, newName] of replacements) {
    // Replace type/interface declarations
    finalCode = finalCode.replace(
      new RegExp(`^(export\\s+)?(interface|type)\\s+${oldName}\\b`, 'gm'),
      `$1$2 ${newName}`
    );

    // Replace type references (but not property names)
    // This regex looks for the type name followed by common type syntax patterns
    finalCode = finalCode.replace(
      new RegExp(`\\b${oldName}\\b(?=\\s*[;,\\]\\)\\}\\|&<>]|$)`, 'g'),
      newName
    );
  }

  return finalCode;
}

// Helper to get clean model name (used for both Cloudflare and external models)
const getCleanModelName = (model: ApiModel): string => {
  if (model.tags.includes('external')) {
    // External model clean name mapping
    if (model.name === 'bge-embeddings') return 'embeddings';
    else if (model.name === 'piiranha-pii') return 'pii-detection';
    else if (model.name === 'llama-3.1-8b-instruct') return 'llama-3.1-8b-external';
    return model.name;
  } else {
    // Cloudflare model clean name mapping (same logic as generateModelCatalog)
    const strippedName = model.name
      .replace(/^@[a-zA-Z0-9-]+\//, '') // Remove @cf/, @hf/ prefixes
      .replace(/^[a-zA-Z0-9-]+\//, ''); // Remove vendor/ prefixes like meta/, openai/, etc.
    
    // Apply name mapping if available (MODEL_NAME_MAPPING would be used here)
    return strippedName;
  }
};

function generateUnifiedTypeMappings(
  models: ApiModel[],
  modelTypeMap: Record<string, { input?: string; output?: string }>,
  catalogEntries: string[]
): string {
  const inputEntries: string[] = [];
  const outputEntries: string[] = [];

  models.forEach(model => {
    const types = modelTypeMap[model.name];
    if (!types) return;

    // Only include models that have both input and output types successfully generated
    if (types.input && types.output) {
      inputEntries.push(`  '${model.name}': ${types.input};`);
      outputEntries.push(`  '${model.name}': ${types.output};`);
    } else {
      console.warn(`⚠ Excluding ${model.name} from type mappings - missing ${!types.input ? 'input' : 'output'} type`);
    }
  });

  // Extract capabilities from catalog entries 
  const getCapabilityFromCatalog = (modelName: string): string => {
    const entry = catalogEntries.find(entry => entry.includes(`name: '${modelName}'`));
    if (!entry) return 'chat';
    const capabilityMatch = entry.match(/capability: '([^']+)'/);
    return capabilityMatch?.[1] || 'chat';
  };

  // Generate lists of models by category using catalog capabilities
  const externalChatModels = models
    .filter(m => m.tags.includes('external') && getCapabilityFromCatalog(getCleanModelName(m)) === 'chat')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
  
  const embeddingModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'embeddings')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const audioModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'audio')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const ttsModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'tts')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const imageGenerationModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'image-generation')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const textClassificationModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'text-classification')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const imageClassificationModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'image-classification')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const translationModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'translation')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const summarizationModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'summarization')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');
    
  const visionModels = models
    .filter(m => getCapabilityFromCatalog(getCleanModelName(m)) === 'vision')
    .map(m => `'${getCleanModelName(m)}'`)
    .join(' | ');

  // Create unified type mappings using conditional types based on model catalog
  return `/** Generated input types for all AI models */
${inputEntries.map(entry => `type ${entry.split("'")[1]?.replace(/[^a-zA-Z0-9]/g, '_')}_Input = ${entry.split(': ')[1]}`).join('\n')}

/** Generated output types for all AI models */
${outputEntries.map(entry => `type ${entry.split("'")[1]?.replace(/[^a-zA-Z0-9]/g, '_')}_Output = ${entry.split(': ')[1]}`).join('\n')}

/** Unified input type mapping using conditional types based on model catalog */
export type AiModelInputMap = {
  [K in AvailableModel]: 
    K extends 'pii-detection' ? { prompt: string } :
    K extends ${embeddingModels || 'never'} ? { input: string | string[]; model?: string; encoding_format?: 'float' | 'base64'; dimensions?: number } :
    K extends ${ttsModels || 'never'} ? { text: string; model?: string; voice?: string; speed?: number; response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm' } :
    K extends ${audioModels || 'never'} ? AudioInput :
    K extends ${imageGenerationModels || 'never'} ? ImageGenerationInput :
    K extends ${textClassificationModels || 'never'} ? TextClassificationInput :
    K extends ${imageClassificationModels || 'never'} ? ImageClassificationInput :
    K extends ${translationModels || 'never'} ? TranslationInput :
    K extends ${summarizationModels || 'never'} ? SummarizationInput :
    K extends ${visionModels || 'never'} ? VisionInput :
    K extends ${externalChatModels || 'never'} ? OpenAIChatInputExternal :
    OpenAIChatInput;
};

/** Unified output type mapping using conditional types based on model catalog */
export type AiModelOutputMap = {
  [K in AvailableModel]: 
    K extends 'pii-detection' ? { pii_detection: Array<{ entity_type: string; text: string; start: number; end: number; confidence: number }> } :
    K extends ${embeddingModels || 'never'} ? OpenAIEmbeddingOutput :
    K extends ${ttsModels || 'never'} ? { audio: ArrayBuffer | Uint8Array; response_format?: string } :
    K extends ${audioModels || 'never'} ? OpenAIAudioOutput :
    K extends ${imageGenerationModels || 'never'} ? ImageGenerationOutput :
    K extends ${textClassificationModels || 'never'} ? TextClassificationOutput :
    K extends ${imageClassificationModels || 'never'} ? ImageClassificationOutput :
    K extends ${translationModels || 'never'} ? TranslationOutput :
    K extends ${summarizationModels || 'never'} ? SummarizationOutput :
    K extends ${visionModels || 'never'} ? VisionOutput :
    OpenAIChatOutput;
};

/** Union of all available AI models */
export type AiModel = AvailableModel;`;
}

function generateModelCatalog(models: ApiModel[]): string {
  const catalogEntries: string[] = [];
  const seenModelNames = new Set<string>();
  
  // Sort models to prioritize external over cloudflare (external models come last in array)
  const sortedModels = [...models].sort((a, b) => {
    const aIsExternal = a.tags.includes('external') || a.tags.includes('model-router');
    const bIsExternal = b.tags.includes('external') || b.tags.includes('model-router');
    
    // External models come last (higher priority)
    if (aIsExternal && !bIsExternal) return 1;
    if (!aIsExternal && bIsExternal) return -1;
    return 0;
  });
  
  sortedModels.forEach(model => {
    let capability = 'chat';
    
    // Determine capability directly from Cloudflare API task name
    const taskToCapability = {
      'Text Generation': 'chat',
      'Text Embeddings': 'embeddings', 
      'Text Classification': 'text-classification',
      'Text-to-Speech': 'tts',
      'Automatic Speech Recognition': 'audio',
      'Image-to-Text': 'vision',
      'Text-to-Image': 'image-generation',
      'Image Classification': 'image-classification',
      'Translation': 'translation',
      'Summarization': 'summarization',
      'Dumb Pipe': 'audio' // Special case for audio turn detection models like smart-turn-v2
    };
    
    // Use API task name for primary classification
    capability = taskToCapability[model.task?.name as keyof typeof taskToCapability] || 'chat';
    
    
    // Handle special cases that aren't in Cloudflare API (external models)
    if (model.name === 'pii-detection' || model.name === 'piiranha-pii') {
      capability = 'pii-detection';
    }

    // Determine provider
    let provider = 'cloudflare';
    if (model.tags.includes('external') || model.tags.includes('model-router')) {
      provider = 'external';
    }

    // Create clean user-facing name and store full provider model name
    let cleanName = model.name;
    let providerModel = model.name;
    
    if (provider === 'cloudflare') {
      // Remove @cf/, @hf/, etc. prefixes AND vendor prefixes for user-facing name
      const strippedName = model.name
        .replace(/^@[a-zA-Z0-9-]+\//, '') // Remove @cf/, @hf/ prefixes
        .replace(/^[a-zA-Z0-9-]+\//, ''); // Remove vendor/ prefixes like meta/, openai/, etc.
      
      // Apply name mapping if available, otherwise use stripped name
      cleanName = MODEL_NAME_MAPPING[strippedName] || strippedName;
      providerModel = model.name; // Keep full name for provider
    } else if (provider === 'external') {
      // Handle external model name mapping for documentation consistency
      if (model.name === 'llama-3.1-8b-instruct') {
        cleanName = 'llama-3.1-8b-external';
      } else if (model.name === 'bge-embeddings') {
        cleanName = 'embeddings';
      } else if (model.name === 'piiranha-pii') {
        cleanName = 'pii-detection';
      } else {
        cleanName = model.name;
      }
      providerModel = model.name; // Keep original name for routing
    }

    // Skip if we've already seen this model name (prioritizing external over cloudflare)
    if (seenModelNames.has(cleanName)) {
      console.log(`⚠ Skipping duplicate model name '${cleanName}' from ${provider} (${model.name})`);
      return;
    }
    seenModelNames.add(cleanName);

    // Escape strings for JavaScript
    const escapedDescription = (model.description || 'No description available')
      .replace(/\\/g, '\\\\')
      .replace(/'/g, "\\'")
      .replace(/\r?\n/g, ' ')
      .replace(/\r/g, ' ');

    
    catalogEntries.push(`  {
    name: '${cleanName}',
    capability: '${capability}',
    provider: '${provider}',
    providerModel: '${providerModel}',
    description: '${escapedDescription}'
  }`);
  });

  return `/** Complete catalog of all available AI models */
export const MODEL_CATALOG = [
${catalogEntries.join(',\n')}
] as const;

/** Available model names */
export type AvailableModel = typeof MODEL_CATALOG[number]['name'];

/** Model capabilities */
export type ModelCapability = 'chat' | 'embeddings' | 'audio' | 'tts' | 'pii-detection' | 'image-generation' | 'text-classification' | 'image-classification' | 'translation' | 'summarization' | 'vision';

/** Model providers */
export type ModelProvider = 'cloudflare' | 'external';

/** Model catalog entry */
export interface ModelCatalogEntry {
  name: string;
  capability: ModelCapability;
  provider: ModelProvider;
  providerModel: string;
  description: string;
}

/** Get all models by capability */
export function getModelsByCapability(capability: ModelCapability): ModelCatalogEntry[] {
  return MODEL_CATALOG.filter(model => model.capability === capability);
}

/** Get model information by name */
export function getModelInfo(modelName: AvailableModel): ModelCatalogEntry | undefined {
  return MODEL_CATALOG.find(model => model.name === modelName);
}

/** OpenAI-compatible chat input interface */
export interface OpenAIChatInput {
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: string;
  }>;
  model?: string;
  temperature?: number;
  max_tokens?: number;
  stream?: boolean;
  response_format?: {
    type: 'json_object' | 'text';
  };
}

/** OpenAI-compatible chat input interface for external models (requires model field) */
export interface OpenAIChatInputExternal extends Omit<OpenAIChatInput, 'model'> {
  model: string; // Required for external model routing
}

/** OpenAI-compatible chat output interface */
export interface OpenAIChatOutput {
  choices: Array<{
    message: {
      role: 'assistant';
      content: string;
    };
    finish_reason?: string;
  }>;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/** OpenAI-compatible embedding output interface */
export interface OpenAIEmbeddingOutput {
  data: Array<{
    embedding: number[];
    index: number;
  }>;
  model?: string;
  usage?: {
    prompt_tokens: number;
    total_tokens: number;
  };
}

/** OpenAI-compatible audio output interface */
export interface OpenAIAudioOutput {
  text: string;
}

/** Image generation input interface */
export interface ImageGenerationInput {
  prompt: string;
  model?: string;
  n?: number;
  size?: string;
  quality?: string;
  style?: string;
  response_format?: 'url' | 'b64_json';
}

/** Image generation output interface */
export interface ImageGenerationOutput {
  data: Array<{
    url?: string;
    b64_json?: string;
  }>;
}

/** Text classification input interface */
export interface TextClassificationInput {
  text: string;
  model?: string;
}

/** Text classification output interface */
export interface TextClassificationOutput {
  label: string;
  score: number;
}

/** Image classification input interface */
export interface ImageClassificationInput {
  image: File | Blob | string;
  model?: string;
}

/** Image classification output interface */
export interface ImageClassificationOutput {
  label: string;
  score: number;
}

/** Translation input interface */
export interface TranslationInput {
  text: string;
  source_lang?: string;
  target_lang: string;
  model?: string;
}

/** Translation output interface */
export interface TranslationOutput {
  translation: string;
  source_lang?: string;
  target_lang: string;
}

/** Summarization input interface */
export interface SummarizationInput {
  text: string;
  max_length?: number;
  min_length?: number;
  model?: string;
}

/** Summarization output interface */
export interface SummarizationOutput {
  summary: string;
}

/** Vision input interface */
export interface VisionInput {
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: Array<{
      type: 'text' | 'image_url';
      text?: string;
      image_url?: {
        url: string; // Can be URL or data:image/... URI
        detail?: 'low' | 'high' | 'auto';
      };
    }>;
  }>;
  model: string; // Required to make it compatible with OpenAIChatInputExternal
  max_tokens?: number;
  temperature?: number;
  stream?: boolean;
}

/** Vision output interface */
export interface VisionOutput {
  choices: Array<{
    message: {
      role: 'assistant';
      content: string;
    };
    finish_reason?: string;
  }>;
}`;
}

function generateBaseTypes(): string {
  return `/** Configuration options for AI gateway requests */
export type GatewayOptions = {
  /** Unique identifier for the request */
  id: string;
  /** Cache key for the request */
  cacheKey?: string;
  /** Time-to-live in seconds for cache entries */
  cacheTtl?: number;
  /** Whether to bypass cache for this request */
  skipCache?: boolean;
  /** Additional metadata to attach to the request */
  metadata?: Record<string, number | string | boolean | null | bigint>;
  /** Whether to collect logs for this request */
  collectLog?: boolean;
  /** Event ID for tracking */
  eventId?: string;
  /** Request timeout in milliseconds */
  requestTimeoutMs?: number;
};

/** Retry configuration for gateway requests */
export type GatewayRetries = {
  /** Maximum number of retries */
  maxRetries?: number;
  /** Backoff strategy */
  backoffStrategy?: 'exponential' | 'linear' | 'fixed';
  /** Initial delay in milliseconds */
  initialDelay?: number;
  /** Maximum delay in milliseconds */
  maxDelay?: number;
};

/** General options for AI operations */
export type AiOptions = {
  /** Process the request asynchronously as a batch */
  queueRequest?: boolean;
  /** Return the raw Response object instead of parsed data */
  returnRawResponse?: boolean;
  /** Gateway-specific configuration */
  gateway?: GatewayOptions;
  /** URL prefix for API endpoints */
  prefix?: string;
  /** Additional HTTP headers to include */
  extraHeaders?: Record<string, string>;
};

/** Extended options for AI operations including smart bucket authentication */
export interface ExtendedAiOptions extends AiOptions {
  includeTimingData?: boolean;
  stream?: boolean;
  
  smartBucketAuth?: {
    bucketId: string;
    secret: string;
  };
};`;
}

function generateStandardizedInterfaces(): string {
  return `// ========================================
// STANDARDIZED PUBLIC INTERFACES
// ========================================

/** Reranker models (bge-reranker-base, etc.) */
export interface RerankerInput {
  query: string;
  documents: string[];
  top_k?: number;
}

/** Summarization models (bart-large-cnn, etc.) */
export interface SummarizationInput {
  text: string;
  max_length?: number;
  min_length?: number;
}

/** Translation models (m2m100-1.2b, etc.) */
export interface TranslationInput {
  text: string;
  source_language?: string;
  target_language: string;
}

/** Text Classification models (distilbert-sst-2-int8, etc.) */
export interface TextClassificationInput {
  text: string;
  labels?: string[];
}

/** Image Generation models (flux-1-schnell, stable-diffusion, etc.) */
export interface ImageGenerationInput {
  prompt: string;
  negative_prompt?: string;
  width?: number;
  height?: number;
  steps?: number;
  guidance_scale?: number;
}

/** Image Classification models (resnet-50, etc.) */
export interface ImageClassificationInput {
  image: string | File | Blob; // URL, File, or Blob
  prompt?: string;
}

/** Vision models (llava-1.5-7b, etc.) */
export interface VisionInput {
  messages: Array<{
    role: 'system' | 'user' | 'assistant';
    content: Array<{
      type: 'text' | 'image_url';
      text?: string;
      image_url?: {
        url: string; // Can be URL or data:image/... URI
        detail?: 'low' | 'high' | 'auto';
      };
    }>;
  }>;
  model: string; // Required to make it compatible with OpenAIChatInputExternal
  max_tokens?: number;
  temperature?: number;
  stream?: boolean;
}

/** TTS models (aura-1, melotts, etc.) */
export interface TTSInput {
  text: string;
  voice?: string;
  speed?: number;
  response_format?: 'mp3' | 'wav' | 'ogg';
}

/** Audio models (whisper variants, etc.) - Standardized format for RPC serialization */
export interface AudioInput {
  audio: number[]; // Audio data as number array for RPC serialization
  contentType: string; // MIME type (e.g., 'audio/mpeg', 'audio/wav')
  language?: string;
  prompt?: string;
  response_format?: 'json' | 'text' | 'srt' | 'vtt';
}

// ========================================
// STANDARDIZED OUTPUT INTERFACES
// ========================================

/** Reranker output interface */
export interface RerankerOutput {
  ranked_documents: Array<{
    index: number;
    document: string;
    relevance_score: number;
  }>;
}

/** Summarization output interface */
export interface SummarizationOutput {
  summary: string;
}

/** Translation output interface */
export interface TranslationOutput {
  translation: string;
  source_lang?: string;
  target_lang: string;
}

/** Text classification output interface */
export interface TextClassificationOutput {
  label: string;
  score: number;
}

/** Image generation output interface */
export interface ImageGenerationOutput {
  data: Array<{
    url?: string;
    b64_json?: string;
  }>;
}

/** Image classification output interface */
export interface ImageClassificationOutput {
  label: string;
  score: number;
}

/** Vision output interface */
export interface VisionOutput {
  choices: Array<{
    message: {
      role: 'assistant';
      content: string;
    };
    finish_reason?: string;
  }>;
}

/** TTS output interface */
export interface TTSOutput {
  audio: ArrayBuffer | Uint8Array;
  response_format?: string;
}

/** Audio output interface */
export interface AudioOutput {
  text: string;
}`;
}

function createSchemaSignature(schema: JsonSchema): string {
  // Create a normalized string representation for comparison that includes property names
  function normalizeSchema(obj: any): any {
    if (obj === null || typeof obj !== 'object') {
      return obj;
    }

    if (Array.isArray(obj)) {
      return obj.map(normalizeSchema);
    }

    const normalized: any = {};
    // Sort keys to ensure consistent ordering
    const sortedKeys = Object.keys(obj).sort();
    for (const key of sortedKeys) {
      normalized[key] = normalizeSchema(obj[key]);
    }
    return normalized;
  }

  return JSON.stringify(normalizeSchema(schema));
}

async function loadModelRouterConfig(): Promise<{ models: ApiModel[], schemas: Record<string, ModelSchema> }> {
  try {
    if (!fs.existsSync(MODEL_ROUTER_CONFIG)) {
      console.log(`No model router config found at ${MODEL_ROUTER_CONFIG}`);
      return { models: [], schemas: {} };
    }

    const content = fs.readFileSync(MODEL_ROUTER_CONFIG, 'utf-8');
    const config = JSON.parse(content) as ModelRouterConfig;

    console.log(`Loading external models from model router config with ${config.providers.length} providers`);

    const models: ApiModel[] = [];
    const schemas: Record<string, ModelSchema> = {};

    // Extract all unique models from providers
    const uniqueModels = new Set<string>();
    config.providers.forEach(provider => {
      provider.models.forEach(model => uniqueModels.add(model));
    });

    // Create ApiModel entries for external models
    uniqueModels.forEach(modelName => {
      // Determine capability based on model name patterns - using same logic as generateModelCatalog
      let capability = 'chat';
      let taskName = 'Text Generation';
      
      if (modelName.includes('whisper')) {
        capability = 'audio';
        taskName = 'Automatic Speech Recognition';
      } else if (modelName === 'bge-embeddings') {
        // Rename HuggingFace bge-embeddings to just 'embeddings' to match docs
        capability = 'embeddings';
        taskName = 'Text Embeddings';
      } else if (modelName.includes('embedding') || modelName.includes('bge')) {
        capability = 'embeddings';
        taskName = 'Text Embeddings';
      } else if (modelName === 'piiranha-pii') {
        capability = 'pii-detection';
        taskName = 'PII Detection';
      } else if (modelName.includes('melotts') || modelName.includes('aura')) {
        capability = 'tts';
        taskName = 'Text to Speech';
      } else if (modelName.includes('llava') || modelName.includes('vision') || modelName === 'llama-4-maverick-17b') {
        capability = 'vision';
        taskName = 'Vision Language Model';
      }

      models.push({
        id: modelName,
        name: modelName,
        description: `External model routed through model-router: ${modelName}`,
        task: {
          id: capability,
          name: taskName,
          description: `${taskName} via external model router`
        },
        created_at: new Date().toISOString(),
        tags: ['external', 'model-router'],
        properties: []
      });

      // Create schema for external models
      if (capability === 'audio') {
        // Whisper-like models
        schemas[modelName] = {
          success: true,
          result: {
            input: {
              type: 'object',
              properties: {
                file: {
                  type: 'string',
                  format: 'binary',
                  description: 'Audio file to transcribe'
                },
                model: {
                  type: 'string',
                  description: 'Model to use for transcription',
                  default: modelName
                },
                language: {
                  type: 'string',
                  description: 'Language of the audio'
                },
                prompt: {
                  type: 'string',
                  description: 'Optional prompt to guide transcription'
                },
                response_format: {
                  type: 'string',
                  enum: ['json', 'text', 'srt', 'verbose_json', 'vtt'],
                  default: 'json'
                },
                temperature: {
                  type: 'number',
                  minimum: 0,
                  maximum: 1,
                  default: 0
                }
              },
              required: ['file']
            },
            output: {
              type: 'object',
              properties: {
                text: {
                  type: 'string',
                  description: 'Transcribed text'
                }
              },
              required: ['text']
            }
          }
        };
      } else if (capability === 'embeddings') {
        // Embedding models
        schemas[modelName] = {
          success: true,
          result: {
            input: {
              type: 'object',
              properties: {
                input: {
                  oneOf: [
                    { type: 'string' },
                    { type: 'array', items: { type: 'string' } }
                  ],
                  description: 'Text to embed'
                },
                model: {
                  type: 'string',
                  description: 'Model to use for embeddings',
                  default: modelName
                },
                encoding_format: {
                  type: 'string',
                  enum: ['float', 'base64'],
                  default: 'float'
                },
                dimensions: {
                  type: 'integer',
                  description: 'Number of dimensions in the embedding'
                }
              },
              required: ['input']
            },
            output: {
              type: 'object',
              properties: {
                data: {
                  type: 'array',
                  items: {
                    type: 'object',
                    properties: {
                      embedding: {
                        type: 'array',
                        items: { type: 'number' }
                      },
                      index: {
                        type: 'integer'
                      }
                    },
                    required: ['embedding', 'index']
                  }
                },
                model: {
                  type: 'string'
                },
                usage: {
                  type: 'object',
                  properties: {
                    prompt_tokens: { type: 'integer' },
                    total_tokens: { type: 'integer' }
                  }
                }
              },
              required: ['data']
            }
          }
        };
      } else {
        // Chat/completion models
        schemas[modelName] = {
          success: true,
          result: {
            input: {
              type: 'object',
              properties: {
                messages: {
                  type: 'array',
                  items: {
                    type: 'object',
                    properties: {
                      role: {
                        type: 'string',
                        enum: ['system', 'user', 'assistant']
                      },
                      content: {
                        type: 'string'
                      }
                    },
                    required: ['role', 'content']
                  }
                },
                model: {
                  type: 'string',
                  default: modelName
                },
                temperature: {
                  type: 'number',
                  minimum: 0,
                  maximum: 2,
                  default: 0.7
                },
                max_tokens: {
                  type: 'integer',
                  minimum: 1,
                  default: 4096
                },
                stream: {
                  type: 'boolean',
                  default: false
                },
                response_format: {
                  type: 'object',
                  properties: {
                    type: {
                      type: 'string',
                      enum: ['json_object', 'text'],
                      default: 'text'
                    }
                  }
                }
              },
              required: ['messages']
            },
            output: {
              type: 'object',
              properties: {
                choices: {
                  type: 'array',
                  items: {
                    type: 'object',
                    properties: {
                      message: {
                        type: 'object',
                        properties: {
                          role: {
                            type: 'string',
                            enum: ['assistant']
                          },
                          content: {
                            type: 'string'
                          }
                        },
                        required: ['role', 'content']
                      },
                      finish_reason: {
                        type: 'string'
                      }
                    },
                    required: ['message']
                  }
                },
                usage: {
                  type: 'object',
                  properties: {
                    prompt_tokens: { type: 'integer' },
                    completion_tokens: { type: 'integer' },
                    total_tokens: { type: 'integer' }
                  }
                }
              },
              required: ['choices']
            }
          }
        };
      }
    });

    console.log(`Loaded ${models.length} external models from model router config`);
    return { models, schemas };
  } catch (error) {
    console.warn('Failed to load model router config:', error);
    return { models: [], schemas: {} };
  }
}

async function loadCustomModels(): Promise<{ models: ApiModel[], schemas: Record<string, ModelSchema> }> {
  try {
    if (!fs.existsSync(CUSTOM_MODELS_FILE)) {
      console.log(`No custom models file found at ${CUSTOM_MODELS_FILE}`);
      return { models: [], schemas: {} };
    }

    const content = fs.readFileSync(CUSTOM_MODELS_FILE, 'utf-8');
    const config = JSON.parse(content) as CustomModelsConfig;

    console.log(`Loading ${config.models.length} custom models from ${CUSTOM_MODELS_FILE}`);

    const models: ApiModel[] = config.models.map(m => ({
      id: m.name,
      name: m.name,
      description: m.description,
      task: m.task,
      created_at: new Date().toISOString(),
      tags: ['custom'],
      properties: []
    }));

    const schemas: Record<string, ModelSchema> = {};
    config.models.forEach(m => {
      if (m.schema) {
        schemas[m.name] = {
          success: true,
          result: {
            input: m.schema.input,
            output: m.schema.output
          }
        };
      }
    });

    console.log(`Loaded ${models.length} custom models with ${Object.keys(schemas).length} schemas`);
    return { models, schemas };
  } catch (error) {
    console.warn('Failed to load custom models:', error);
    return { models: [], schemas: {} };
  }
}

async function generateAiTypeScript(): Promise<void> {
  try {
    console.log('Fetching models...');
    const cloudflareModels = await fetchModels();
    console.log(`Found ${cloudflareModels.length} Cloudflare models`);

    // Load custom models and external models from model router
    const { models: customModels, schemas: customSchemas } = await loadCustomModels();
    const { models: externalModels, schemas: externalSchemas } = await loadModelRouterConfig();

    // Merge models
    const models = [...cloudflareModels, ...customModels, ...externalModels];
    console.log(`Total models: ${models.length} (${cloudflareModels.length} Cloudflare + ${customModels.length} custom + ${externalModels.length} external)`);

    // Group models by task
    const groups = groupModelsByTask(models);

    // Start with custom and external schemas
    const schemas: Record<string, ModelSchema> = { ...customSchemas, ...externalSchemas };

    // Fetch schemas for Cloudflare models with batching to avoid rate limits
    console.log('Fetching Cloudflare schemas with batching...');
    await batchPromises(
      cloudflareModels,
      async (model) => {
        const schema = await fetchSchema(model.name);
        if (schema) {
          schemas[model.name] = schema;
          console.log(`✓ Fetched schema for ${model.name}`);
        } else {
          console.log(`✗ Failed to fetch schema for ${model.name}`);
        }
      },
      5 // Limit to 5 concurrent requests
    );

    const cloudflareSchemaCount = Object.keys(schemas).length - Object.keys(customSchemas).length - Object.keys(externalSchemas).length;
    console.log(`Fetched ${cloudflareSchemaCount} Cloudflare schemas`);
    console.log(`Total schemas: ${Object.keys(schemas).length} (${cloudflareSchemaCount} Cloudflare + ${Object.keys(customSchemas).length} custom + ${Object.keys(externalSchemas).length} external)`);

    // Log which Cloudflare models failed to fetch schemas
    const failedCloudflareModels = cloudflareModels.filter(model => !schemas[model.name]);
    if (failedCloudflareModels.length > 0) {
      console.warn(`Failed to fetch schemas for ${failedCloudflareModels.length} Cloudflare models:`, failedCloudflareModels.map(m => m.name));
    }

    // Deduplicate schemas and generate shared types
    const generatedTypes: string[] = [];
    const modelTypeMap: Record<string, { input?: string; output?: string }> = {};
    const inputSchemaSignatureMap: Record<string, string> = {}; // signature -> type name for inputs
    const outputSchemaSignatureMap: Record<string, string> = {}; // signature -> type name for outputs
    const inputSchemaTypeCounter: Record<string, number> = {}; // base name -> count for inputs
    const outputSchemaTypeCounter: Record<string, number> = {}; // base name -> count for outputs
    const usedTypeNames = new Set<string>(); // Track all used type names globally

    // Process each model's schema and deduplicate
    for (const model of models) {
      // Skip problematic Cloudflare gpt-oss models that cause TypeScript compilation errors
      if (model.name === '@cf/openai/gpt-oss-20b' || model.name === '@cf/openai/gpt-oss-120b') {
        console.log(`⚠ Skipping problematic Cloudflare model ${model.name} (complex oneOf schema)`);
        continue;
      }
      
      const schema = schemas[model.name];
      if (!schema?.result) continue;

      modelTypeMap[model.name] = {};

      // Process input schema
      if (schema.result.input) {
        const inputSignature = createSchemaSignature(schema.result.input);

        if (inputSchemaSignatureMap[inputSignature]) {
          // Reuse existing input type
          modelTypeMap[model.name]!.input = inputSchemaSignatureMap[inputSignature];
        } else {
          // Generate new input type
          const baseTypeName = 'AiInput';
          const count = inputSchemaTypeCounter[baseTypeName] || 0;
          const inputTypeName = count === 0 ? baseTypeName : `${baseTypeName}${count + 1}`;
          inputSchemaTypeCounter[baseTypeName] = count + 1; // Increment counter immediately
          
          try {
            usedTypeNames.add(inputTypeName);
            const inputType = await generateTypeFromSchema(
              schema.result.input,
              inputTypeName,
              model.name,
              usedTypeNames,
              false // isOutput = false for input schemas
            );
            
            // Only proceed if type generation succeeded
            generatedTypes.push(inputType);
            inputSchemaSignatureMap[inputSignature] = inputTypeName;
            modelTypeMap[model.name]!.input = inputTypeName;
            console.log(`✓ Generated input type ${inputTypeName} for ${model.name}`);
          } catch (error) {
            // Remove from usedTypeNames if generation failed
            usedTypeNames.delete(inputTypeName);
            console.warn(`✗ Failed to generate input type for ${model.name}: ${error instanceof Error ? error.message : 'Unknown error'}`);
            // Don't assign input type to model if generation failed
          }
        }
      }

      // Process output schema
      if (schema.result.output) {
        const outputSignature = createSchemaSignature(schema.result.output);

        if (outputSchemaSignatureMap[outputSignature]) {
          // Reuse existing output type
          modelTypeMap[model.name]!.output = outputSchemaSignatureMap[outputSignature];
        } else {
          // Generate new output type
          const baseTypeName = 'AiOutput';
          const count = outputSchemaTypeCounter[baseTypeName] || 0;
          const outputTypeName = count === 0 ? baseTypeName : `${baseTypeName}${count + 1}`;
          outputSchemaTypeCounter[baseTypeName] = count + 1; // Increment counter immediately
          
          try {
            usedTypeNames.add(outputTypeName);
            const outputType = await generateTypeFromSchema(
              schema.result.output,
              outputTypeName,
              model.name,
              usedTypeNames,
              true // isOutput = true for output schemas
            );
            
            // Only proceed if type generation succeeded
            generatedTypes.push(outputType);
            outputSchemaSignatureMap[outputSignature] = outputTypeName;
            modelTypeMap[model.name]!.output = outputTypeName;
            console.log(`✓ Generated output type ${outputTypeName} for ${model.name}`);
          } catch (error) {
            // Remove from usedTypeNames if generation failed
            usedTypeNames.delete(outputTypeName);
            console.warn(`✗ Failed to generate output type for ${model.name}: ${error instanceof Error ? error.message : 'Unknown error'}`);
            // Don't assign output type to model if generation failed
          }
        }
      }
    }

    console.log(`Generated ${generatedTypes.length} unique types from ${Object.keys(schemas).length} schemas`);

    // Generate model catalog
    const modelCatalog = generateModelCatalog(models);

    // Generate unified type mappings with catalog-based conditional types
    const catalogEntries = models.map(model => {
      // Use the same logic as generateModelCatalog for consistency
      let capability = 'chat';
      
      // Determine capability directly from Cloudflare API task name
      const taskToCapability = {
        'Text Generation': 'chat',
        'Text Embeddings': 'embeddings', 
        'Text Classification': 'text-classification',
        'Text-to-Speech': 'tts',
        'Automatic Speech Recognition': 'audio',
        'Image-to-Text': 'vision',
        'Text-to-Image': 'image-generation',
        'Image Classification': 'image-classification',
        'Translation': 'translation',
        'Summarization': 'summarization',
        'Dumb Pipe': 'audio' // Special case for audio turn detection models like smart-turn-v2
      };
      
      // Use API task name for primary classification
      capability = taskToCapability[model.task?.name as keyof typeof taskToCapability] || 'chat';
      
      // Handle special cases that aren't in Cloudflare API (external models)
      if (model.name === 'pii-detection' || model.name === 'piiranha-pii') {
        capability = 'pii-detection';
      } else if (model.name.includes('llava') || model.name.includes('vision') || model.name === 'llama-4-maverick-17b') {
        capability = 'vision';
      }
      
      
      // Get clean name using our helper function  
      const cleanName = getCleanModelName(model);
      
      return `name: '${cleanName}', capability: '${capability}'`;
    });
    const unifiedTypeMappings = generateUnifiedTypeMappings(models, modelTypeMap, catalogEntries);

    // Generate base types
    const baseTypes = generateBaseTypes();

    // Combine all parts  
    const output = `/* eslint-disable */
${modelCatalog}

${baseTypes}

${generateStandardizedInterfaces()}

${generatedTypes.join('\n\n')}

${unifiedTypeMappings}

/** Generic async response type for queued AI requests */
export interface AiAsyncResponse {
  /** The async request id that can be used to obtain the results */
  request_id: string;
}

/** Main interface for AI operations
 * @remarks
 * Provides a unified interface for running various AI models across different tasks.
 * Each model type has its own specific input and output types.
 */
export interface Ai {
  run<T extends AiModel, I extends AiModelInputMap[T] = AiModelInputMap[T], O extends ExtendedAiOptions = ExtendedAiOptions>(
    model: T,
    inputs: I,
    options?: O,
  ): Promise<
    I extends { stream: true } ? ReadableStream :
    O extends { returnRawResponse: true } ? Response :
    O extends { queueRequest: true } ? AiAsyncResponse :
    AiModelOutputMap[T]
  >;
}
`;

    // Ensure output directory exists
    const outputDir = path.dirname(OUTPUT_FILE);
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    fs.writeFileSync(OUTPUT_FILE, output);

    console.log(`Generated TypeScript file: ${OUTPUT_FILE}`);
    console.log(`Model groups found: ${Object.keys(groups).join(', ')}`);
    console.log(`Fetched ${Object.keys(schemas).length} total schemas out of ${models.length} models`);
    console.log(`Generated individual model types: ${Object.keys(modelTypeMap).length}`);
    console.log(`Success rate: ${Math.round(Object.keys(schemas).length / models.length * 100)}%`);

  } catch (error) {
    console.error('Error generating AI TypeScript:', error);
    process.exit(1);
  }
}

// Run the script
generateAiTypeScript();
